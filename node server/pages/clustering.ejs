<html>
   <head>
      <title>Machine Learning Server Processing: Clustering</title>
      <link rel="stylesheet" type="text/css" href="page.css">
   </head>

   <body> 
    <h1>Description</h1>
        <p>This page will show the clustering representation  of the data. The program will try to analyze the uploaded data and cluster the unique classifications.
            If there are no classifications, then clustering will be used to determine the number of possible classifications. This page will show the results of the data in 2 dimensions.
            If the data set is beyond 2 dimensions, then the data will go under dimension redution. This page will different clustering algorithms and different dimension reduction techniques.
        </p>
    
    <h2>Menu List</h2>
    <ul>
        <li>
            <a href = "#K-Means">K-Means Algorithm</a>
        </li>
        <li>
            <a href ="#Mean-Shift">Mean-Shift Algorithm</a>
        </li>
        <li>
            <a href = "#EM">Expectation Maximation</a>
        </li>
        <li>
            <a href = "#Dimension Reduction">Dimension Reduction Techniques</a>
        </li>
        <li>
            <a href = "#Navigation">Navigation Bar</a>
        </li>
    </ul> 
            
        <div id = "K-Means">
            <h3>K-Means</h3>
                <p>K-Means is an iterative algorithm that tries to partition a dataset into K pre-defined non-overlapping clusters where each data point belongs to only one group. 
                It assigns data points to a cluster such that variance between the cluster's centeroid and the datapoint is minimized across the set of clusters.
                 More simliar data points are tightly clustered whileas loosely related data points are less dense.
                </p>
        </div>
        
        <div id = "K-Means + PCA" class = "image-tables">
           <img src = "<%=config.K_Means_PCA_Identify%>"/>
           <img src = "<%=config.K_Means_PCA_Possesion%>"/>
        </div>
        <div id = "K-Means + TSNE" class = "image-tables">
            <img src = "<%=config.K_Means_TSNE_Identify%>"/>
            <img src = "<%=config.K_Means_TSNE_Possesion%>"/>
        </div>
        <div id = "K-Means + UMAP" class = "image-tables">
            <img src = "<%=config.K_Means_UMAP_Identify%>"/>
            <img src = "<%=config.K_Means_UMAP_Possesion%>"/>
        </div>

        <div id = "Mean-Shift">
            <h3>Mean-Shift</h3>
                <p>Mean-Shift relies on Kernal Density Estimation. Based on the paremeter of kernal bandwidth, data points are clustered within a kernal. 
                    Using a gaussian distribution, the algorithm seeks to minimize the probabilitistic variance. 
                    Larger the kernal bandwidth, larger the allowed variance which a larger amount of data points being selected for a given cluster.
                    The algorithm uses the kernal distribution to dynamically determine the number of clusters.
                </p>
        </div>
  
        <div id = "Mean-Shift + PCA" class = "image-tables">
            <img src = "<%=config.Mean_Shift_PCA_Identify%>"/>
            <img src = "<%=config.Mean_Shift_PCA_Possesion%>"/>
        </div>
        <div id = "Mean-Shift + TSNE" class = "image-tables">
            <img src = "<%=config.Mean_Shift_TSNE_Identify%>"/>
            <img src = "<%=config.Mean_Shift_TSNE_Possesion%>"/>
        </div>
        <div id = "Mean-Shift + UMAP" class = "image-tables">
            <img src = "<%=config.Mean_Shift_UMAP_Identify%>"/>
            <img src = "<%=config.Mean_Shift_UMAP_Possesion%>"/>
        </div>
        
        <div id = "EM">
            <h3>Expectation Maximation</h3>
                <p>Expectation Maximation is a probabilitistic algorithm that conducts soft clustering. Each cluster is a gaussian distribution where the variance and mean is inferred.
                    The model iteratively creates random gaussian models across data points for a set parameter and iteratively computes clusters. Unlike K-Means, this algorithm allows
                    for data points to belong to clusters on a scale. This confidence scale leads to the soft clustering nature of this algorithm
                </p>
        </div>
        <div id = "EM + PCA" class = "image-tables">
            <img src = "<%=config.EM_PCA_Identify%>"/>
            <img src = "<%=config.EM_PCA_Possesion%>"/>
        </div>
        <div id = "EM + TSNE" class = "image-tables">
            <img src = "<%=config.EM_TSNE_Identify%>"/>
            <img src = "<%=config.EM_TSNE_Possesion%>"/>
        </div>
        <div id = "EM + UMAP" class = "image-tables">
            <img src = "<%=config.EM_UMAP_Identify%>"/>
            <img src = "<%=config.EM_UMAP_Possesion%>"/>
        </div>

        <div id = "Dimension Reduction">
            <h3>Principal Component Analysis</h3>
            <p>
                PCA is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components.
                 In other words, PCA will conduct feature elimination feature extraction to linearly compress a dataset to a lower dimensionality. The algorithm fisrt takes the variables and creates a matrix
                 It then computes the covariancee --relationship-- between the data in the matrix, and his process is repeated according to the number of principal components. 
                 There are limitations to PCA. The algorthim is not scale invariant. 
                 It maximizes variance between variables
                 If the variables are correlated, then PCA will be effective in compressing the data. Otherwise, PCA orders them according to their variances
                 PCA utilizes mean and variance matricies. If the data does not follow this distribution, mixed results will arise
            </p>
            <h3>TSNE</h3>
            <p>
                T-SNE is a machine learning algorithm for visualization. It takes high dimensionality data and compresses it down to a lower, but more managable set of data dimensions.
                The algorithm works by calculating the probability of similarity of points in high-dimensional space and calculating the probability of similarity of points in the corresponding low-dimensional space. Neigbors are chosen by a Gaussian
                It then minimizes the difference between these conditional probabilitiesin higher-dimensional and lower-dimensional space via
                the minimized sum of Kullback-Leibler divergence using a gradient descent method. There are limitations to TSNE. First, it captures local relationships of data points.
                It requires hyperparameter tuning and is sensitive to noisy Patterns.
                The algorithm is very computation heavy. It may be advised to use PCA or other dimension reduction techniques as a intermediary before using t-SNE, especially if the data is sparse
                The algorithm scales quadratically with number of objects also requring more memory
            </p>
            <h3>Uniform Manifold Approximation Projection</h3>
            <p>
                UMAP is a non-linear dimension reduction technique that can be used for visualisation. The embedding is found by searching for a low dimensional projection of the data that has the closest possible equivalent fuzzy topological structure through the use of manifolds. This technique is new and can be found in this research paper: McInnes, L, Healy, J, UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction, ArXiv e-prints 1802.03426, 2018
                Before the algorithm starts, the algorithms assumes the following: uniformly distributed Riemannian manifold data, locally constant Riemannian metric, locally connected manifold.
                With these assumptions: the algorithm acts under topography and manifold theory. When you deal with higher dimension space, it can be imagined as a multidimensional shape encased by a 2D planar skin. This planar skin can be represented into lower dimension like a 2D unfoled representation of a cube
                This algorithm uses fuzzy representations to model the data that can be utilized to derive metrics of a higher dimensional space. UMAP is a newer technique, needs to be more rigorously tested
            </p>
        </div>


        <div id = "Navigation">   
            <h2>Navigation Bar</h2>

                <li><a href="/clustering">Clustering</a></li>
                <li><a href="/data-upload">Upload Data</a></li>
              </ul> 
        </div>
   </body>
</html>